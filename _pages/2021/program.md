---
title: Program
permalink: /2021/program/
---

# <span class="time">Program</span>

Insights 2021 will be a hybrid workshop. The poster sessions will be conducted online, in gather.town. The other sessions will have a mixture of virtual and on-site speakers and attendees.

All times are local time (Punta Cana, GMT-4).

<span class="time">8:45–9:00</span> Opening remarks

<span class="time">9:00–10:00</span> Invited talk: [Noah Smith](https://homes.cs.washington.edu/~nasmith/) (University of Washington / Allen Institute for AI) 

**What Makes a Result Negative?**
> In this talk, I’ll discuss the frame of “negative results” that is used to describe outcomes in the research process, specifically in modern natural language processing.  I’ll link this frame to some assumptions that I think have been mostly harmful to research and researchers.  I’ll argue for a few first principles that can help us to design research projects in such a way that useful new information is likely to emerge, no matter what the experiments show.  Unfortunately, I can’t offer a foolproof method for avoiding “negative results,” but I do hope to move our field’s discourse to be better aligned with its broader goals, and offer some reminders about the incredible variety of ways to contribute to those goals.  Though this talk won’t spend much time highlighting the research findings of my mentees and collaborators, and the views expressed should only be taken as my own (not theirs), the worldview I discuss has developed through interactions with them, for which I am grateful.
 
<span class="time">10:00–11:15</span> Poster session 1

<span class="time">11:15–11:30</span> Social break / coffee time

<span class="time">11:30–12:30</span> Invited talk: [Bonnie Webber](https://homepages.inf.ed.ac.uk/bonnie/) (University of Edinburgh)

**The Reviewers and the Reviewed: Institutional Memory and Institutional Incentives**
> Everyone has their own stories about unfair reviewers, misguided reviewers,  and reviewers who just don't seem to get it. A Workshop on "Insights from  Negative Results" then seems just the place to reflect on who reviews are for, what purpose they serve for authors and reviewers, and what may be gained or lost from recent changes to conference reviewing.

<span class="time">12:30–13:00</span> Oral presentation session 1

<span class="time">13:00–14:00</span> Lunch break

<span class="time">14:00–15:00</span> Invited talk: [Zachary Lipton](http://zacklipton.com/) (Carnegie Mellon University)<br/>

**Some Results on Label Shift and Label Noise**
> In this talk I will discuss distribution shift, both as an obstacle to be overcome to achieve generalization, and as a device for obtaining generalization guarantees. In the first part, I will discuss the problem of label shift, where the proportion among the labels can shift but the class conditional distributions do not change, including connections to some practical problems and some theoretical results. Then I will discuss a new work in which we deliberately perturb the distribution of training data in order to obtain a generalization guarantee.
 
<span class="time">15:00–16:15</span> Poster session 2

<span class="time">16:15–16:30</span> Social break / coffee time

<span class="time">16:30–17:00</span> Oral presentation session 2

<span class="time">17:00–18:00</span> Invited talk: [Rachael Tatman](http://www.rctatman.com/) (Rasa) <br/>

**Chatbots can be good: What we learn from unhappy users**
> It’s no secret that chatbots have a bad reputation: no one enjoys a cyclical, frustrating conversation when all you need is a quick answer to an urgent question. But chatbots can, in fact, be good. Having bad conversations can help us get there before they’re ever deployed
> This talk will draw on both academic and industry knowledge to discuss problems like:
>  - What do users’ reactions to unsuccessful systems tell us about what successful systems should look like?
>  - Are we evaluating the right things… or the easy to measure things?
>  - Do we really have to look at user data? If so, when and how often?
>  - When, if ever, should we retire old methods?
 
<span class="time">18:00–18:15</span> Closing remarks