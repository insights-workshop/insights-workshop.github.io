---
title: Accepted papers
permalink: /2022/accepted/
---

## <span style="color:#267CB9"> Accepted Papers </span>
- *On Isotropy Calibration of Transformer Models* <br /> Yue Ding, Karolis Martinkus, Damian Pascual, Simon Clematide and Roger Wattenhofer
- *Do Dependency Relations Help in the Task of Stance Detection?* <br /> Alessandra Teresa Cignarella, Cristina Bosco and Paolo Rosso
- *Evaluating the Practical Utility of Confidence-score based Techniques for Unsupervised Open-world Classification* <br /> Sopan Khosla and Rashmi Gangadharaiah
- *Extending the Scope of Out-of-Domain: Examining QA models in multiple subdomains* <br /> Chenyang Lyu, Jennifer Foster and Yvette Graham
- *What Do You Get When You Cross Beam Search with Nucleus Sampling?* <br /> Uri Shaham and Omer Levy
- *How Much Do Modifications to Transformer Language Models Affect Their Ability to Learn Linguistic Knowledge?* <br /> Simeng Sun, Brian Dillon and Mohit Iyyer
- *Cross-lingual Inflection as a Data Augmentation Method for Parsing* <br/> Alberto Mu˜noz-Ortiz, Carlos G´omez-Rodr´ıguez and David Vilares
- *Is BERT Robust to Label Noise? A Study on Learning with Noisy Labels in Text Classification* <br/> Dawei Zhu, Michael A. Hedderich, Fangzhou Zhai, David Ifeoluwa Adelani and Dietrich Klakow
- *Ancestor-to-Creole Transfer is Not a Walk in the Park* <br/> Heather Lent, Emanuele Bugliarello and Anders Søgaard
- *What GPT Knows About Who is Who* <br/> Xiaohan Yang, Eduardo Peynetti, Vasco Meerman and Chris Tanner
- *Evaluating Biomedical Word Embeddings for Vocabulary Alignment at Scale in the UMLS Metathesaurus Using Siamese Networks* <br/> Goonmeet Bajaj, Vinh Nguyen, Thilini Wijesiriwardene, Hong Yung Yip, Vishesh Javangula,
Amit P. Sheth, Srinivasan Parthasarathy and Olivier Bodenreider
- *On the Impact of Data Augmentation on Downstream Performance in Natural Language Processing* <br/> Itsuki Okimura, Machel Reid, Makoto Kawano and Yutaka Matsuo
- *Can Question Rewriting Help Conversational Question Answering?* <br/> Etsuko Ishii, Yan Xu, Samuel Cahyawijaya and Bryan Wilie
- *Clustering Examples in Multi-Dataset Benchmarks with Item Response Theory* <br/> Pedro Rodriguez, Phu Mon Htut, John P. Lalor and Jo˜ao Sedoc
- *On the Limits of Evaluating Embodied Agent Model Generalization Using Validation Sets* <br/> Hyounghun Kim, Aishwarya Padmakumar, Di Jin, Mohit Bansal and Dilek Hakkani-Tur
- *Do Data-based Curricula Work?* <br/> Maxim K. Surkov, Vladislav D. Mosin and Ivan P. Yamshchikov
- *The Document Vectors Using Cosine Similarity Revisited* <br/> Zhang Bingyu and Nikolay Arefyev
- *Challenges in including extra-linguistic context in pre-trained language models* <br/> Ionut Teodor Sorodoc, Laura Aina and Gemma Boleda
- *Label Errors in BANKING77* <br/> Cecilia Ying and Stephen Thomas
- *Pathologies of Pre-trained Language Models in Few-shot Fine-tuning* <br/> Hanjie Chen, Guoqing Zheng, Ahmed Hassan Awadallah and Yangfeng Ji
- *An Empirical study to understand the Compositional Prowess of Neural Dialog Models* <br/> Vinayshekhar Bannihatti Kumar, Vaibhav Kumar, Mukul Bhutani and Alexander Rudnicky
- *Combining Extraction and Generation for Constructing Belief-Consequence Causal Links* <br/> Maria Alexeeva, Allegra A. Beal A. Beal and Mihai Surdeanu
- *Replicability under Near-Perfect Conditions – A Case-Study from Automatic Summarization* <br/> Margot Mieskes
- *BPE beyond Word Boundary: How NOT to use Multi Word Expressions in Neural Machine Translation* <br/> Dipesh Kumar and Avijit Thawani
- *Pre-trained language models evaluating themselves - A comparative study* <br /> Philipp Koch, Matthias Aßenmacher and Christian Heumann
