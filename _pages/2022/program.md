---
title: Program
permalink: /2022/program/
---

## <span style="color:#267CB9"> Program </span>

Thursday, May 26, 2022 <br />

<span class="time">8:45–9:00</span> Opening remarks

<span class="time">9:00–10:00</span> Invited talk: [Barbara Plank](https://bplank.github.io/) (LMU Munich) 

**Off the Beaten Track: On Serendipity and Turning "Failures" into Signal** [VIDEO](https://youtu.be/_A5vEuqXOM8)

> In this talk, I'll first reflect upon the research process in current NLP and discuss how the principle of serendipity can play an important role in the design of research projects. In the second part, I will provide a series of examples to illustrate how something perceived as "noise" can yield research opportunities. These include leveraging  fortuitous data like meta-data for low-resource NLP, human disagreement in labelling, and I will also provide some puzzling results on an understudied BERT detail.

<span class="time">10:00–10:30</span> Thematic Session 1: Improving Evaluation Practices

> - *Replicability under Near-Perfect Conditions – A Case-Study from Automatic Summarization* <br /> Margot Mieskes [[PDF]](https://aclanthology.org/2022.insights-1.23/), [[Video]](https://underline.io/events/284/sessions/10984/lecture/52739-replicability-under-near-perfect-conditions-%E2%80%93-a-case-study-from-automatic-summarization)
> - *On the Limits of Evaluating Embodied Agent Model Generalization Using Validation Sets* <br /> Hyounghun Kim, Aishwarya Padmakumar, Di Jin, Mohit Bansal and Dilek Hakkani-Tur [[PDF]](https://aclanthology.org/2022.insights-1.15/), [[Video]](https://underline.io/events/284/sessions/10984/lecture/52730-on-the-limits-of-evaluating-embodied-agent-model-generalization-using-validation-sets)

<span class="time">10:30–11:30</span> Coffee Break

<span class="time">11:30–12:00</span> Thematic Session 2: Transformers
> - *How Much Do Modifications to Transformer Language Models Affect Their Ability to Learn Linguistic Knowledge?* <br /> Simeng Sun, Brian Dillon and Mohit Iyyer [[PDF]](https://aclanthology.org/2022.insights-1.6/), [[Video]](https://underline.io/events/284/sessions/10984/lecture/52720-how-much-do-modifications-to-transformer-language-models-affect-their-ability-to-learn-linguistic-knowledgequestion)
> - *Pathologies of Pre-trained Language Models in Few-shot Fine-tuning* <br /> Hanjie Chen, Guoqing Zheng, Ahmed Hassan Awadallah and Yangfeng Ji [[PDF]](https://aclanthology.org/2022.insights-1.20/), [[Video]](https://underline.io/events/284/sessions/10984/lecture/52736-pathologies-of-pre-trained-language-models-in-few-shot-fine-tuning)
> - *On Isotropy Calibration of Transformer Models* <br /> Yue Ding, Karolis Martinkus, Damian Pascual, Simon Clematide and RogerWattenhofer [[PDF]](https://aclanthology.org/2022.insights-1.1/), [[Video]](https://underline.io/events/284/sessions/10984/lecture/52726-on-isotropy-calibration-of-transformer-models)

<span class="time">12:00–12:30</span> Thematic Session 3: Towards Better Data
> - *Do Data-based Curricula Work?* <br /> Maxim K. Surkov, Vladislav D. Mosin and Ivan P. Yamshchikov [[PDF]](https://aclanthology.org/2022.insights-1.16/)
> - *Clustering Examples in Multi-Dataset Benchmarks with Item Response Theory* <br /> Pedro Rodriguez, Phu Mon Htut, John P. Lalor and Jo˜ao Sedoc [[PDF]](https://aclanthology.org/2022.insights-1.14/)
> - *On the Impact of Data Augmentation on Downstream Performance in Natural Language Processing* <br /> Itsuki Okimura, Machel Reid, Makoto Kawano and Yutaka Matsuo [[PDF]](https://aclanthology.org/2022.insights-1.12/), [[Video]](https://underline.io/events/284/sessions/10984/lecture/52727-on-the-impact-of-data-augmentation-on-downstream-performance-in-natural-language-processing)

<span class="time">12:30–14:00</span> Lunch

<span class="time">14:00–15:00</span> **Panel Discussion: How Bad are Annotation Disagreements, Really?**

*Panelists:* [Margot Mieskes](https://sis.h-da.de/personen/professor-innen-auf-einen-blick/prof-dr-margot-mieskes/) (University of Applied Sciences, Darmstadt), [Barbara Plank](https://bplank.github.io/) (LMU Munich), [Massimo Poesio](http://www.eecs.qmul.ac.uk/profiles/poesiomassimo.html) (Queen Mary University of London), [Bonnie Webber](https://homepages.inf.ed.ac.uk/bonnie/) (University of Edinburgh) 

*Moderator:* [Anna Rogers](https://annargrs.github.io) (University of Copenhagen)

<span class="time">15:00–15:30</span> Coffee Break

<span class="time">15:30–16:00</span> Thematic Session 4: Linguistically Informed Analysis
> - *Do Dependency Relations Help in the Task of Stance Detection?* <br /> Alessandra Teresa Cignarella, Cristina Bosco and Paolo Rosso [[PDF]](https://aclanthology.org/2022.insights-1.2/), [[Video]](https://underline.io/events/284/sessions/10984/lecture/52732-do-dependency-relations-help-in-the-task-of-stance-detectionquestion)
> - *BPE beyond Word Boundary: How NOT to use Multi Word Expressions in Neural Machine Translation* <br /> Dipesh Kumar and Avijit Thawani [[PDF]](https://aclanthology.org/2022.insights-1.24/), [[Video]](https://underline.io/events/284/sessions/10984/lecture/52741-bpe-beyond-word-boundary-how-not-to-use-multi-word-expressions-in-neural-machine-translation)
> - *Challenges in including extra-linguistic context in pre-trained language models* <br /> Ionut Teodor Sorodoc, Laura Aina and Gemma Boleda [[PDF]](https://aclanthology.org/2022.insights-1.18/), [[Video]](https://underline.io/events/284/sessions/10984/lecture/52734-challenges-in-including-extra-linguistic-context-in-pre-trained-language-models)

<span class="time">16:00–17:00</span> Invited talk: [Tal Linzen](https://tallinzen.net/) (NYU)

**Sensitivity to Initial Weights in Out-of-distribution Generalization** [VIDEO](https://youtu.be/uDBsTLKaquU)

> The results of experiments that involve training neural networks can be sensitive to the networks’ initial weights. In this talk I will review work from my group and others that shows that such sensitivity can be quite dramatic when the network is evaluated on its out-of-distribution generalization accuracy, as is typically the case with the challenge datasets popular in the “interpretability” community. In one experiment, when we fine-tuned BERT 100 times on the same dataset, in-distribution test set accuracy was reasonably stable, but out-of-distribution behavior differed qualitatively across runs. The recent MultiBERTs project, where BERT was retrained 25 times, demonstrates that this variability persists across pretrained models as well. This variability makes it harder to interpret the results on a single fine-tuning run of a challenge dataset, and highlights a potentially underappreciated consequence of neural networks’ weak inductive biases.

<span class="time">17:00–18:00</span> Poster Session

> * *Evaluating the Practical Utility of Confidence-score based Techniques for Unsupervised Open-world Classification* <br/> Sopan Khosla, Rashmi Gangadharaiah [[PDF]](https://aclanthology.org/2022.insights-1.3/), [[Video]](https://underline.io/events/284/sessions/10984/lecture/52740-evaluating-the-practical-utility-of-confidence-score-based-techniques-for-unsupervised-open-world-classification)
> * *Extending the Scope of Out-of-Domain: Examining QA models in multiple subdomains* <br/> Chenyang Lyu, Jennifer Foster, Yvette Graham [[PDF]](https://aclanthology.org/2022.insights-1.4/), [[Video]](https://underline.io/events/284/sessions/10984/lecture/52743-extending-the-scope-of-out-of-domain-examining-qa-models-in-multiple-subdomains)
> * *What Do You Get When You Cross Beam Search with Nucleus Sampling?* <br/> Uri Shaham, Omer Levy [[PDF]](https://aclanthology.org/2022.insights-1.5/), [[Video]]()
> * *Cross-lingual Inflection as a Data Augmentation Method for Parsing* <br/> Alberto Muñoz-Ortiz, Carlos Gómez-Rodríguez, David Vilares [[PDF]](https://aclanthology.org/2022.insights-1.7/), [[Video]](https://underline.io/events/284/sessions/10984/lecture/52721-cross-lingual-inflection-as-a-data-augmentation-method-for-parsing)
> * *Is BERT Robust to Label Noise? A Study on Learning with Noisy Labels in Text Classification* <br/> Dawei Zhu, Michael Hedderich, Fangzhou Zhai, David Adelani, Dietrich Klakow [[PDF]](https://aclanthology.org/2022.insights-1.8/), [[Video]](https://underline.io/events/284/sessions/10984/lecture/52722-is-bert-robust-to-label-noisequestion-a-study-on-learning-with-noisy-labels-in-text-classification)
> * *Ancestor-to-Creole Transfer is Not a Walk in the Park* <br/> Heather Lent, Emanuele Bugliarello, Anders Søgaard [[PDF]](https://aclanthology.org/2022.insights-1.9/)
> * *What GPT Knows About Who is Who* <br/> Xiaohan Yang, Eduardo Peynetti, Vasco Meerman, Chris Tanner [[PDF]](https://aclanthology.org/2022.insights-1.10/), [[Video]](https://underline.io/events/284/sessions/10984/lecture/52724-what-gpt-knows-about-who-is-who)
> * *Evaluating Biomedical Word Embeddings for Vocabulary Alignment at Scale in the UMLS Metathesaurus Using Siamese Networks* <br/> Goonmeet Bajaj, Vinh Nguyen, Thilini Wijesiriwardene, Hong Yung Yip, Vishesh Javangula, Amit Sheth, Srinivasan Parthasarathy, Olivier Bodenreider [[PDF]](https://aclanthology.org/2022.insights-1.11/)
> * *Can Question Rewriting Help Conversational Question Answering?* <br/> Etsuko Ishii, Yan Xu, Samuel Cahyawijaya, Bryan Wilie [[PDF]](https://aclanthology.org/2022.insights-1.13/), [[Video]](https://underline.io/events/284/sessions/10984/lecture/52728-can-question-rewriting-help-conversational-question-answeringquestion)
> * *The Document Vectors Using Cosine Similarity Revisited* <br/> Zhang Bingyu, Nikolay Arefyev [[PDF]](https://aclanthology.org/2022.insights-1.17/), [[Video]](https://underline.io/events/284/sessions/10984/lecture/52733-the-document-vectors-using-cosine-similarity-revisited)
> * *Label Errors in BANKING77* <br/> Cecilia Ying, Stephen Thomas [[PDF]](https://aclanthology.org/2022.insights-1.19/), [[Video]](https://underline.io/events/284/sessions/10984/lecture/52735-label-errors-in-banking77)
> * *An Empirical study to understand the Compositional Prowess of Neural Dialog Models* <br/> Vinayshekhar Kumar, Vaibhav Kumar, Mukul Bhutani, Alexander Rudnicky [[PDF]](https://aclanthology.org/2022.insights-1.21/), [[Video]](https://underline.io/events/284/sessions/10984/lecture/52737-an-empirical-study-to-understand-the-compositional-prowess-of-neural-dialog-models)
> * *Combining Extraction and Generation for Constructing Belief-Consequence Causal Links* <br/> Maria Alexeeva, Allegra A. Beal Cohen, Mihai Surdeanu [[PDF]](https://aclanthology.org/2022.insights-1.22/), [[Video]](https://underline.io/events/284/sessions/10984/lecture/52738-combining-extraction-and-generation-for-constructing-belief-consequence-causal-links)
> * *Pre-trained language models evaluating themselves - A comparative study* <br/> Philipp Koch, Matthias Aßenmacher, Christian Heumann [[PDF]](https://aclanthology.org/2022.insights-1.25/), [[Video]](https://underline.io/events/284/sessions/10984/lecture/52742-pre-trained-language-models-evaluating-themselves---a-comparative-study)

<span class="time">18:00–18:10</span> Closing Remarks
